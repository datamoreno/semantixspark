{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "from pyspark.sql import SparkSession\nfrom ibm_botocore.client import Config\nimport ibm_boto3", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "spark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark SQL\") \\\n    .getOrCreate()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "# ARQUIVOS SALVOS EM UM BUCKET GRATUITO DA IBM\n# CREDENCIAIS DO BUCKET\n\ncredentials_7 = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-9ec669c5-6c1d-4d70-810c-1941badb231e',\n    'IBM_API_KEY_ID': 'Ta-EpXfATe3TsngSYxlAdhNCO5n_zrlh5GL7x7-XOauv',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': 'semantixspark-donotdelete-pr-uclrrmcdckxuwn',\n    'FILE': 'access_log_Jul95'\n}\n\ncredentials_8 = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-9ec669c5-6c1d-4d70-810c-1941badb231e',\n    'IBM_API_KEY_ID': 'Ta-EpXfATe3TsngSYxlAdhNCO5n_zrlh5GL7x7-XOauv',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': 'semantixspark-donotdelete-pr-uclrrmcdckxuwn',\n    'FILE': 'access_log_Aug95'\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "# CLIENT PARA DOWNLOAD DOS ARQUIVOS\n\n# JULHO\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials_7['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials_7['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials_7['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials_7['ENDPOINT'])\n\ncos.download_file(Bucket=credentials_7['BUCKET']\n                  ,Key='access_log_Jul95'\n                  ,Filename='access_log_Jul95')\n\n# AGOSTO\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials_8['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials_8['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials_8['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials_8['ENDPOINT'])\n\ncos.download_file(Bucket=credentials_8['BUCKET']\n                  ,Key='access_log_Aug95'\n                  ,Filename='access_log_Aug95')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "# lEITURA COM O SPARK\n\nfiles = ['access_log_Jul95','access_log_Aug95']\n\ndf1 = spark.read.load(files\n                     , format='csv'\n                     , sep=' '\n                     , inferSchema='true'\n                     , header='false'\n                    )\n\ndf2 = df1.createOrReplaceTempView(\"NASA\")\n\nsqlDF = spark.sql(\"SELECT * FROM NASA\")\nsqlDF.show()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+---+---+--------------------+------+--------------------+---+-----+\n|                 _c0|_c1|_c2|                 _c3|   _c4|                 _c5|_c6|  _c7|\n+--------------------+---+---+--------------------+------+--------------------+---+-----+\n|        199.72.81.55|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /history/apol...|200| 6245|\n|unicomp6.unicomp.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200| 3985|\n|      199.120.110.21|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/miss...|200| 4085|\n|  burger.letters.com|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|304|    0|\n|      199.120.110.21|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/miss...|200| 4179|\n|  burger.letters.com|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/NASA-...|304|    0|\n|  burger.letters.com|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200|    0|\n|     205.212.115.106|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200| 3985|\n|         d104.aa.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200| 3985|\n|      129.94.144.152|  -|  -|[01/Jul/1995:00:0...|-0400]|      GET / HTTP/1.0|200| 7074|\n|unicomp6.unicomp.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200|40310|\n|unicomp6.unicomp.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/NASA-...|200|  786|\n|unicomp6.unicomp.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/KSC-l...|200| 1204|\n|         d104.aa.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/coun...|200|40310|\n|         d104.aa.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/NASA-...|200|  786|\n|         d104.aa.net|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/KSC-l...|200| 1204|\n|      129.94.144.152|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/ksclo...|304|    0|\n|      199.120.110.21|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /images/launc...|200| 1713|\n|ppptky391.asahi-n...|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /facts/about_...|200| 3977|\n|  net-1-141.eden.com|  -|  -|[01/Jul/1995:00:0...|-0400]|GET /shuttle/miss...|200|34029|\n+--------------------+---+---+--------------------+------+--------------------+---+-----+\nonly showing top 20 rows\n\n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "query = ''' \n        CREATE OR REPLACE TEMPORARY VIEW FATO_NASA\n        AS\n        SELECT _c0 as host\n            , FROM_UNIXTIME(UNIX_TIMESTAMP(SUBSTRING( concat( _c3 , _c4 ) , 2 , 20), 'dd/MMM/yyyy:HH:mm:ss'),'yyyy-MM-dd HH:mm:ss') as timestamp\n            , _c5 as requisicao\n            , _c6 as retorno\n            , _c7 as bytes\n        FROM NASA\n        '''\nsqlDF = spark.sql(query)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 83
        }, 
        {
            "source": "sqlDF = spark.sql('SELECT * FROM FATO_NASA')\nsqlDF.show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------------------------+-------------------+--------------------------------------------------------------+-------+-----+\n|host                     |timestamp          |requisicao                                                    |retorno|bytes|\n+-------------------------+-------------------+--------------------------------------------------------------+-------+-----+\n|199.72.81.55             |1995-07-01 00:00:01|GET /history/apollo/ HTTP/1.0                                 |200    |6245 |\n|unicomp6.unicomp.net     |1995-07-01 00:00:06|GET /shuttle/countdown/ HTTP/1.0                              |200    |3985 |\n|199.120.110.21           |1995-07-01 00:00:09|GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0     |200    |4085 |\n|burger.letters.com       |1995-07-01 00:00:11|GET /shuttle/countdown/liftoff.html HTTP/1.0                  |304    |0    |\n|199.120.110.21           |1995-07-01 00:00:11|GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0  |200    |4179 |\n|burger.letters.com       |1995-07-01 00:00:12|GET /images/NASA-logosmall.gif HTTP/1.0                       |304    |0    |\n|burger.letters.com       |1995-07-01 00:00:12|GET /shuttle/countdown/video/livevideo.gif HTTP/1.0           |200    |0    |\n|205.212.115.106          |1995-07-01 00:00:12|GET /shuttle/countdown/countdown.html HTTP/1.0                |200    |3985 |\n|d104.aa.net              |1995-07-01 00:00:13|GET /shuttle/countdown/ HTTP/1.0                              |200    |3985 |\n|129.94.144.152           |1995-07-01 00:00:13|GET / HTTP/1.0                                                |200    |7074 |\n|unicomp6.unicomp.net     |1995-07-01 00:00:14|GET /shuttle/countdown/count.gif HTTP/1.0                     |200    |40310|\n|unicomp6.unicomp.net     |1995-07-01 00:00:14|GET /images/NASA-logosmall.gif HTTP/1.0                       |200    |786  |\n|unicomp6.unicomp.net     |1995-07-01 00:00:14|GET /images/KSC-logosmall.gif HTTP/1.0                        |200    |1204 |\n|d104.aa.net              |1995-07-01 00:00:15|GET /shuttle/countdown/count.gif HTTP/1.0                     |200    |40310|\n|d104.aa.net              |1995-07-01 00:00:15|GET /images/NASA-logosmall.gif HTTP/1.0                       |200    |786  |\n|d104.aa.net              |1995-07-01 00:00:15|GET /images/KSC-logosmall.gif HTTP/1.0                        |200    |1204 |\n|129.94.144.152           |1995-07-01 00:00:17|GET /images/ksclogo-medium.gif HTTP/1.0                       |304    |0    |\n|199.120.110.21           |1995-07-01 00:00:17|GET /images/launch-logo.gif HTTP/1.0                          |200    |1713 |\n|ppptky391.asahi-net.or.jp|1995-07-01 00:00:18|GET /facts/about_ksc.html HTTP/1.0                            |200    |3977 |\n|net-1-141.eden.com       |1995-07-01 00:00:19|GET /shuttle/missions/sts-71/images/KSC-95EC-0916.jpg HTTP/1.0|200    |34029|\n+-------------------------+-------------------+--------------------------------------------------------------+-------+-----+\nonly showing top 20 rows\n\n"
                }
            ], 
            "execution_count": 84
        }, 
        {
            "source": "sqlDF = spark.sql('SELECT COUNT(DISTINCT HOST) AS HOSTS_UNICOS FROM FATO_NASA')\nsqlDF.show()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------+\n|HOSTS_UNICOS|\n+------------+\n|      137979|\n+------------+\n\n"
                }
            ], 
            "execution_count": 22
        }, 
        {
            "source": "query = ''' \n        SELECT COUNT(1) AS TOTAL_ERROS_404\n        FROM FATO_NASA\n        WHERE RETORNO = '404'\n        '''\n\nsqlDF = spark.sql(query)\nsqlDF.show()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---------------+\n|TOTAL_ERROS_404|\n+---------------+\n|          20871|\n+---------------+\n\n"
                }
            ], 
            "execution_count": 24
        }, 
        {
            "source": "query = ''' \n        SELECT REQUISICAO\n            , COUNT(1) AS ERROS404\n        FROM FATO_NASA\n        WHERE RETORNO = '404'\n        GROUP BY REQUISICAO\n        ORDER BY COUNT(1) DESC\n        LIMIT 5\n        '''\nsqlDF = spark.sql(query)\nsqlDF.show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---------------------------------------------------------+---------------+\n|REQUISICAO                                               |TOTAL_ERROS_404|\n+---------------------------------------------------------+---------------+\n|GET /pub/winvn/readme.txt HTTP/1.0                       |2004           |\n|GET /pub/winvn/release.txt HTTP/1.0                      |1732           |\n|GET /shuttle/missions/STS-69/mission-STS-69.html HTTP/1.0|682            |\n|GET /shuttle/missions/sts-68/ksc-upclose.gif HTTP/1.0    |426            |\n|GET /history/apollo/a-001/a-001-patch-small.gif HTTP/1.0 |384            |\n+---------------------------------------------------------+---------------+\n\n"
                }
            ], 
            "execution_count": 34
        }, 
        {
            "source": "query = ''' \n        SELECT to_date(TIMESTAMP) AS DATA\n            , COUNT(1) AS ERROS404\n        FROM FATO_NASA\n        WHERE RETORNO = '404'\n        GROUP BY to_date(TIMESTAMP)\n        ORDER BY 1 ASC\n        '''\nsqlDF = spark.sql(query)\nsqlDF.show(100, truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+----------+--------+\n|DATA      |ERROS404|\n+----------+--------+\n|1995-07-01|316     |\n|1995-07-02|291     |\n|1995-07-03|470     |\n|1995-07-04|359     |\n|1995-07-05|497     |\n|1995-07-06|640     |\n|1995-07-07|569     |\n|1995-07-08|302     |\n|1995-07-09|348     |\n|1995-07-10|398     |\n|1995-07-11|471     |\n|1995-07-12|470     |\n|1995-07-13|531     |\n|1995-07-14|411     |\n|1995-07-15|254     |\n|1995-07-16|257     |\n|1995-07-17|406     |\n|1995-07-18|465     |\n|1995-07-19|638     |\n|1995-07-20|428     |\n|1995-07-21|332     |\n|1995-07-22|191     |\n|1995-07-23|233     |\n|1995-07-24|328     |\n|1995-07-25|461     |\n|1995-07-26|336     |\n|1995-07-27|336     |\n|1995-07-28|94      |\n|1995-08-01|243     |\n|1995-08-03|303     |\n|1995-08-04|346     |\n|1995-08-05|236     |\n|1995-08-06|373     |\n|1995-08-07|537     |\n|1995-08-08|390     |\n|1995-08-09|279     |\n|1995-08-10|306     |\n|1995-08-11|263     |\n|1995-08-12|196     |\n|1995-08-13|216     |\n|1995-08-14|287     |\n|1995-08-15|327     |\n|1995-08-16|259     |\n|1995-08-17|271     |\n|1995-08-18|256     |\n|1995-08-19|209     |\n|1995-08-20|312     |\n|1995-08-21|305     |\n|1995-08-22|285     |\n|1995-08-23|345     |\n|1995-08-24|420     |\n|1995-08-25|415     |\n|1995-08-26|366     |\n|1995-08-27|367     |\n|1995-08-28|410     |\n|1995-08-29|420     |\n|1995-08-30|571     |\n|1995-08-31|526     |\n+----------+--------+\n\n"
                }
            ], 
            "execution_count": 91
        }, 
        {
            "source": "query = ''' \n        SELECT SUM(BYTES)*1.0/(1024*1024*1024) as GIGABYTES\n        FROM FATO_NASA\n        '''\nsqlDF = spark.sql(query)\nsqlDF.show(truncate=False)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+\n|GIGABYTES         |\n+------------------+\n|61.024278212338686|\n+------------------+\n\n"
                }
            ], 
            "execution_count": 96
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}